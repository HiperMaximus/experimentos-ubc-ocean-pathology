{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 01:49:10.691476: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-28 01:49:12.189420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-28 01:49:19.080170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "#os.environ['TORCH_LOGS'] = \"+dynamo\"\n",
    "#os.environ['TORCHDYNAMO_VERBOSE'] = \"1\"\n",
    "import warnings\n",
    "# Suppress the symbolic shapes warning\n",
    "# warnings.filterwarnings(\"ignore\", message=\"xindex is not in var_ranges\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import save_image\n",
    "from vae_equivariant_architecture import D4_Equivariant_VAE\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiledImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, image_ids, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_ids = image_ids\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        \n",
    "        # Collect all image paths for the given image IDs\n",
    "        for image_id in image_ids:\n",
    "            image_folder = os.path.join(data_dir, image_id)\n",
    "            for img_name in os.listdir(image_folder):\n",
    "                self.image_paths.append(os.path.join(image_folder, img_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `image_ids` is a list of all folder names (IDs of the original images)\n",
    "data_dir = '../UBC-Ocean-Data/Autoencoder'\n",
    "image_ids = os.listdir(data_dir)  # List of all original image IDs\n",
    "\n",
    "# Split image IDs\n",
    "train_ids, temp_ids = train_test_split(image_ids, test_size=0.3, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=2/3, random_state=42)  # 10% validation, 20% test\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TiledImageDataset(data_dir, train_ids, transform=transform)\n",
    "val_dataset = TiledImageDataset(data_dir, val_ids, transform=transform)\n",
    "test_dataset = TiledImageDataset(data_dir, test_ids, transform=transform)\n",
    "\n",
    "batch_size=2**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10% of training data for each epoch\n",
    "def get_subset_sampler(dataset, percentage=0.1):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    split = int(np.ceil(percentage * dataset_size))\n",
    "    train_indices = indices[:split]\n",
    "    \n",
    "    return SubsetRandomSampler(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f26a1d1b2f546caa90ec027724335a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/100:   0%|          | 0/541 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b66b0893c5a41899ac270a2858c1b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 1/100:   0%|          | 0/66 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The histogram is empty, please file a bug report.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 131\u001b[0m\n\u001b[1;32m    129\u001b[0m         avg_gradient \u001b[38;5;241m=\u001b[39m accumulated_gradients[name] \u001b[38;5;241m/\u001b[39m num_samples\n\u001b[1;32m    130\u001b[0m         avg_gradients[name]\u001b[38;5;241m=\u001b[39mavg_gradient\n\u001b[0;32m--> 131\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGradients/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavg_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Save both model and optimizer states\u001b[39;00m\n\u001b[1;32m    134\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: compiled_vae\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_gradients\u001b[39m\u001b[38;5;124m'\u001b[39m:avg_gradients\n\u001b[1;32m    143\u001b[0m }, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/media/max/f7de66f7-119c-4593-a8ab-02f75c636771/Max/experimentos-ubc-ocean-pathology/venv/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py:499\u001b[0m, in \u001b[0;36mSummaryWriter.add_histogram\u001b[0;34m(self, tag, values, global_step, bins, walltime, max_bins)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bins, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m bins \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    497\u001b[0m     bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_bins\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(\n\u001b[0;32m--> 499\u001b[0m     \u001b[43mhistogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_bins\u001b[49m\u001b[43m)\u001b[49m, global_step, walltime\n\u001b[1;32m    500\u001b[0m )\n",
      "File \u001b[0;32m/media/max/f7de66f7-119c-4593-a8ab-02f75c636771/Max/experimentos-ubc-ocean-pathology/venv/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py:485\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(name, values, bins, max_bins)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer with a histogram.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mThe generated\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m  buffer.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m values \u001b[38;5;241m=\u001b[39m make_np(values)\n\u001b[0;32m--> 485\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmake_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Summary(value\u001b[38;5;241m=\u001b[39m[Summary\u001b[38;5;241m.\u001b[39mValue(tag\u001b[38;5;241m=\u001b[39mname, histo\u001b[38;5;241m=\u001b[39mhist)])\n",
      "File \u001b[0;32m/media/max/f7de66f7-119c-4593-a8ab-02f75c636771/Max/experimentos-ubc-ocean-pathology/venv/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py:530\u001b[0m, in \u001b[0;36mmake_histogram\u001b[0;34m(values, bins, max_bins)\u001b[0m\n\u001b[1;32m    527\u001b[0m limits \u001b[38;5;241m=\u001b[39m limits[start : end \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counts\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m limits\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe histogram is empty, please file a bug report.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    532\u001b[0m sum_sq \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mdot(values)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HistogramProto(\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mmin(),\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mmax(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m     bucket\u001b[38;5;241m=\u001b[39mcounts\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m    541\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: The histogram is empty, please file a bug report."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# Model, optimizer, and compilation\n",
    "latent_dim = 256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae = D4_Equivariant_VAE(latent_dim)\n",
    "compiled_vae = vae.to(device)\n",
    "#compiled_vae = torch.compile(vae,fullgraph=True,dynamic=False).to(device)\n",
    "#compiled_vae.load_state_dict(torch.load('epochs/epoch_10/vae_weights_epoch_10.pth',weights_only=True))\n",
    "\n",
    "optimizer = optim.AdamW(compiled_vae.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min', \n",
    "    factor=0.9, \n",
    "    patience=1,\n",
    "    cooldown=1)\n",
    "\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Select and save 24 images from the test set (ensure to keep this consistent across epochs)\n",
    "n=24\n",
    "fixed_batch = next(iter(DataLoader(test_dataset, batch_size=n, shuffle=True)))\n",
    "for i in range(n):\n",
    "    save_image(fixed_batch[i],fp=f'epochs/example_imgs/img_{i}.png')\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir='runs/vae_experiment')\n",
    "# Log original images to TensorBoard\n",
    "writer.add_images('Original Images', fixed_batch, 0)\n",
    "\n",
    "\n",
    "# sample 10% of data per epoch and log everything\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    sampler = get_subset_sampler(train_dataset, percentage=0.01)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    accumulated_gradients = {name: torch.zeros_like(param) for name, param in compiled_vae.named_parameters()}\n",
    "    compiled_vae.train()\n",
    "    train_loss = 0\n",
    "    num_samples=0\n",
    "    # Use tqdm to create a progress bar for the training loop\n",
    "    with tqdm(total=len(train_loader), desc=f'Training Epoch {epoch + 1}/{num_epochs}', unit='batch', position=0, leave=False) as pbar:\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            recon_batch, mu, logvar = compiled_vae(batch)\n",
    "            loss = compiled_vae.vae_loss(recon_batch, batch, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            for name, param in compiled_vae.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    accumulated_gradients[name] += param.grad.detach().clone()\n",
    "\n",
    "            num_samples+=batch.size()[0]\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)  # Increment the progress bar by 1\n",
    "            pbar.set_postfix({'train_loss': loss.item()})  # Display current loss\n",
    "\n",
    "\n",
    "    train_loss /= num_samples\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "\n",
    "    # Create current directory if doesn't exists\n",
    "    current_dir=f'epochs/epoch_{epoch +1}/'\n",
    "    os.makedirs(current_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Validation loop\n",
    "    compiled_vae.eval()\n",
    "    val_loss = 0\n",
    "    num_samples_val=0\n",
    "    sampler = get_subset_sampler(val_dataset, percentage=0.01)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(val_loader), desc=f'Validation Epoch {epoch + 1}/{num_epochs}', unit='batch',position=1, leave=False) as pbar:\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                recon_batch, mu, logvar = compiled_vae(batch)\n",
    "                loss = compiled_vae.vae_loss(recon_batch, batch, mu, logvar)\n",
    "                val_loss += loss.item()\n",
    "                num_samples_val+=batch.size()[0]\n",
    "\n",
    "                # Update the progress bar\n",
    "                pbar.update(1)  # Increment the progress bar by 1\n",
    "                pbar.set_postfix({'val_loss': loss.item()})  # Display current loss\n",
    "\n",
    "    val_loss /= num_samples_val\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "    # Update the learning rate scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "    # The learning rate in optimizer will be updated automatically if needed\n",
    "    current_lr = scheduler.get_last_lr()[0]  # To check the current learning rate\n",
    "\n",
    "    # At the end of each epoch, save the reconstructions\n",
    "    compiled_vae.eval()\n",
    "    with torch.no_grad():\n",
    "        fixed_batch_epoch = fixed_batch.to(device)\n",
    "        mu, _ = compiled_vae.encode(fixed_batch_epoch)\n",
    "        recon_batch = compiled_vae.decode(mu)\n",
    "        recon_batch=recon_batch.cpu()\n",
    "\n",
    "        # Reverse normalization\n",
    "        recon_batch = (recon_batch*0.5)+0.5 \n",
    "        # Clamp the values to be in the range [0, 1]\n",
    "        recon_batch = torch.clamp(recon_batch, 0, 1)\n",
    "        for i in range(n):\n",
    "            save_image(recon_batch[i],fp=os.path.join(current_dir,f'img_recon_{i}.png'))\n",
    "    \n",
    "    # Log reconstructed images to TensorBoard\n",
    "    writer.add_images('Reconstructed Images', recon_batch, epoch)\n",
    "\n",
    "    # Log the model parameters and accumulated gradients to TensorBoard after the epoch\n",
    "    avg_gradients=copy.deepcopy(accumulated_gradients)\n",
    "    for name, param in compiled_vae.named_parameters():\n",
    "        # Log weights as histogram\n",
    "        if param.data.numel() > 0:\n",
    "            writer.add_histogram(f'Weights/{name}', param, global_step=epoch)\n",
    "\n",
    "        if (param.grad is not None) and (param.grad.numel() > 0):\n",
    "            # Log averaged gradients\n",
    "            avg_gradient = accumulated_gradients[name] / num_samples\n",
    "            if avg_gradient.numel() > 0:  # Check if the averaged gradient is non-empty\n",
    "                avg_gradients[name] = avg_gradient\n",
    "                writer.add_histogram(f'Gradients/{name}', avg_gradient, global_step=epoch)\n",
    "            else:\n",
    "                print(f\"Warning: Averaged gradient for {name} is empty.\")\n",
    "\n",
    "    # Save both model and optimizer states\n",
    "    torch.save({\n",
    "        'epoch': epoch+1,\n",
    "        'model_state_dict': compiled_vae.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss':val_loss,\n",
    "        'num_samples': num_samples,\n",
    "        'avg_gradients':avg_gradients\n",
    "    }, os.path.join(current_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "\n",
    "    # Save best model when validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "        'epoch': epoch+1,\n",
    "        'model_state_dict': compiled_vae.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss':val_loss,\n",
    "        'num_samples': num_samples,\n",
    "        'avg_gradients':avg_gradients\n",
    "        }, os.path.join('epochs/best_model/', 'vae_best_model.pth'))\n",
    "\n",
    "    # Log training and validation losses\n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "\n",
    "    tqdm.write(f'Epoch {epoch + 1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Learning Rate: {current_lr}')\n",
    "\n",
    "\n",
    "\n",
    "# After training loop\n",
    "\n",
    "# Calculate test loss\n",
    "compiled_vae.eval()\n",
    "test_loss = 0\n",
    "num_samples = 0\n",
    "sampler = get_subset_sampler(test_dataset, percentage=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=sampler)\n",
    "with tqdm(total=len(test_loader), desc=f'Validation', unit='batch') as pbar:\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            recon_batch, mu, logvar = compiled_vae(batch)\n",
    "            loss = compiled_vae.vae_loss(recon_batch, batch, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            num_samples += batch.size()[0]\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)  # Increment the progress bar by 1\n",
    "            pbar.set_postfix({'val_loss': loss.item()})  # Display current loss\n",
    "test_loss /= num_samples\n",
    "\n",
    "# Log test losses\n",
    "writer.add_scalar('Loss/Test', test_loss, epoch)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "# Print test loss\n",
    "tqdm.write(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('loss_plot.png')  # Save the plot as an image file\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model when validation loss improves\n",
    "if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    torch.save({\n",
    "        'epoch': epoch+1,\n",
    "        'model_state_dict': compiled_vae.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss':val_loss,\n",
    "        'num_samples': num_samples,\n",
    "        'avg_gradients':avg_gradients\n",
    "        }, os.path.join('epochs/best_model/', 'vae_best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epochs/epoch_1/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
